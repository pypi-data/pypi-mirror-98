#!/usr/bin/env python
# -*- coding: latin-1 -*-
#
#   Copyright 2016-2019 Blaise Frederick
#
#   Licensed under the Apache License, Version 2.0 (the "License");
#   you may not use this file except in compliance with the License.
#   You may obtain a copy of the License at
#
#       http://www.apache.org/licenses/LICENSE-2.0
#
#   Unless required by applicable law or agreed to in writing, software
#   distributed under the License is distributed on an "AS IS" BASIS,
#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#   See the License for the specific language governing permissions and
#   limitations under the License.
#
#
#       $Author: frederic $
#       $Date: 2016/06/14 12:04:50 $
#       $Id: linfit,v 1.4 2016/06/14 12:04:50 frederic Exp $
#
from __future__ import print_function, division
import sys
import getopt
import rapidtide.io as tide_io
import rapidtide.filter as tide_filt
from sklearn.decomposition import FastICA, PCA, SparsePCA


def usage():
    print("usage: temporaldecomp datafile outputroot")
    print("")
    print("required arguments:")
    print("	datafile	- the name of the 3 or 4 dimensional nifti file to fit")
    print("	outputroot	- the root name of the output nifti files")
    print("")
    print("optional arguments:")
    print("	--dmask=DATAMASK       - use DATAMASK to specify which voxels in the data to use")
    print("	--ncomp=NCOMPS         - the number of PCA/ICA components to return (default is to estimate the number")
    print("	--smooth=SIGMA         - spatially smooth the input data with a SIGMA mm kernel")
    print("	--type=TYPE            - type of decomposition to perform, 'pca', 'sparse' or 'ica' - default is 'pca'")
    print("	--nodemean             - do not demean data prior to decomposition")
    print("	--novarnorm            - do not variance normalize data prior to decomposition")
    print("")
    return ()


# set default variable values
usedmask = False
decomptype = 'pca'
pcacomponents = 0.5
icacomponents = None
varnorm = True
demean = True
sigma = 0.0
max_iter = 250
n_init = 100
batch_size = 1000
minibatch = True

# parse command line arguments
try:
    opts, args = getopt.gnu_getopt(sys.argv, 'h',
                                   ["help", "nodemean", "novarnorm", "dmask=", "smooth=", "ncomp=", "type="])
except getopt.GetoptError as err:
    # print(help information and exit:
    print(str(err))  # will print something like "option -a not recognized"
    usage()
    sys.exit(2)

# handle required args first
if len(args) < 3:
    print('spatial fit has 2 required arguments - ', len(args) - 1, 'found')
    usage()
    sys.exit()

datafilename = args[1]
outputrootname = args[2]

for o, a in opts:
    if o == "--dmask":
        usedmask = True
        datamaskname = a
        print('using', datamaskname, 'as data mask')
    elif o == "--ncomp":
        inputnum = float(a)
        if inputnum < 1.0:
            pcacomponents = inputnum
            icacomponenets = None
        else:
            pcacomponents = int(a)
            icacomponents = pcacomponents
    elif o == "--nodemean":
        demean = False
        print('will not demean data prior to decomposition')
    elif o == "--novarnorm":
        varnorm = False
        print('will not variance normalize data prior to decomposition')
    elif o == "--smooth":
        sigma = float(a)
        print('will smooth data with a', sigma, 'mm kernel')
    elif o == "--type":
        decomptype = a
        if decomptype != 'pca' and decomptype != 'ica' and decomptype != 'sparse':
            print('illegal decomposition mode - must be pca or ica')
            sys.exit()
    elif o in ("-h", "--help"):
        usage()
        sys.exit()
    else:
        assert False, "unhandled option"

print('Will perform', decomptype, 'analysis')

# save the command line
tide_io.writevec([' '.join(sys.argv)], outputrootname + '_commandline.txt')

# read in data
print("reading in data arrays")
datafile_img, datafile_data, datafile_hdr, datafiledims, datafilesizes = tide_io.readfromnifti(datafilename)
if usedmask:
    datamask_img, datamask_data, datamask_hdr, datamaskdims, datamasksizes = tide_io.readfromnifti(datamaskname)

xsize, ysize, numslices, timepoints = tide_io.parseniftidims(datafiledims)
xdim, ydim, slicethickness, tr = tide_io.parseniftisizes(datafilesizes)

# check dimensions
if usedmask:
    print("checking mask dimensions")
    if not tide_io.checkspacedimmatch(datafiledims, datamaskdims):
        print('input mask spatial dimensions do not match image')
        exit()
    if not (tide_io.checktimematch(datafiledims, datamaskdims) or datamaskdims[4] == 1):
        print('input mask time dimension does not match image')
        exit()

# save the command line
tide_io.writevec([' '.join(sys.argv)], outputrootname + '_commandline.txt')

# smooth the data
if sigma > 0.0:
    print('smoothing data')
    for i in range(timepoints):
        datafile_data[:, :, :, i] = tide_filt.ssmooth(xdim, ydim, slicethickness, sigma, datafile_data[:, :, :, i])

# allocating arrays
print("reshaping arrays")
numspatiallocs = int(xsize) * int(ysize) * int(numslices)
rs_datafile = datafile_data.reshape((numspatiallocs, timepoints))

print("masking arrays")
if usedmask:
    if datamaskdims[4] == 1:
        proclocs = np.where(datamask_data.reshape(numspatiallocs) > 0.9)
    else:
        proclocs = np.where(np.mean(datamask_data.reshape((numspatiallocs, timepoints)), axis=1) > 0.9)
        rs_mask = datamask_data.reshape((numspatiallocs, timepoints))[proclocs, :]
        rs_mask = np.where(rs_mask > 0.9, 1.0, 0.0)[0]
else:
    datamaskdims = [1, xsize, ysize, numslices, 1]
    themaxes = np.max(rs_datafile, axis=1)
    themins = np.min(rs_datafile, axis=1)
    thediffs = (themaxes - themins).reshape(numspatiallocs)
    proclocs = np.where(thediffs > 0.0)
procdata = rs_datafile[proclocs, :][0]
print(rs_datafile.shape, procdata.shape)

# normalize the individual images
if demean:
    print("demeaning array")
    themean = np.mean(procdata, axis=1)
    print('shape of mean', themean.shape)
    for i in range(procdata.shape[0]):
        procdata[i, :] -= themean[i]

if varnorm:
    print("variance normalizing array")
    thevar = np.var(procdata, axis=1)
    print('shape of mean', themean.shape)
    for i in range(procdata.shape[0]):
        procdata[i, :] /= thevar[i]
    procdata = np.nan_to_num(procdata)

# applying mask
if datamaskdims[4] > 1:
    procdata *= rs_mask

# now perform the decomposition
if decomptype == 'ica':
    print('performing ica decomposition')
    if icacomponents is None:
        print('will return all significant components')
    else:
        print('will return', icacomponents, 'components')
    thefit = FastICA(n_components=icacomponents).fit(procdata)  # Reconstruct signals
    if icacomponents is None:
        thecomponents = thefit.components_[:]
        print(thecomponents.shape[1], 'components found')
    else:
        thecomponents = thefit.components_[0:icacomponents]
        print('returning first', thecomponents.shape[1], 'components found')
else:
    print('performing pca decomposition')
    if pcacomponents < 1.0:
        print('will return the components accounting for', pcacomponents * 100.0, '% of the variance')
    else:
        print('will return', pcacomponents, 'components')
    if decomptype == 'pca':
        thepca = PCA(n_components=pcacomponents)
    else:
        thepca = SparsePCA(n_components=pcacomponents)
    thefit = thepca.fit(procdata)
    thetransform = thepca.transform(procdata)
    theinvtrans = thepca.inverse_transform(thetransform)
    if pcacomponents < 1.0:
        thecomponents = thefit.components_[:]
        thesingvals = thefit.singular_values_[:]
        print('returning', thecomponents.shape[1], 'components')
    else:
        thecomponents = thefit.components_[0:pcacomponents]
        thesingvals = thefit.singular_values_[:pcacomponents]

    # save the eigenvalues
    print('variance explained by component:', 100.0 * thefit.explained_variance_ratio_)
    tide_io.writenpvecs(100.0 * thefit.explained_variance_ratio_, outputrootname + '_explained_variance_pct.txt')

    # save the components
    print("writing component timecourses")
    tide_io.writenpvecs(thecomponents, outputrootname + '_components.txt')

    # save the singular values
    print("writing singular values")
    tide_io.writenpvecs(np.transpose(thesingvals), outputrootname + '_singvals.txt')

    # save the coefficients
    # save the coefficients
    print("writing out the coefficients")
    coefficients = thetransform
    print('coefficients shape:', coefficients.shape)
    theheader = datafile_hdr
    theheader['dim'][4] = coefficients.shape[1]
    tempout = np.zeros((numspatiallocs, coefficients.shape[1]), dtype='float')
    tempout[proclocs, :] = coefficients[:, :]
    tide_io.savetonifti(tempout.reshape((xsize, ysize, numslices, coefficients.shape[1])), datafile_hdr,
                        outputrootname + '_coefficients')

    # save the dimensionality reduced data
    invtransformeddata = theinvtrans
    print("writing fit data")
    theheader = datafile_hdr
    theheader['dim'][4] = invtransformeddata.shape[1]
    tempout = np.zeros((numspatiallocs, invtransformeddata.shape[1]), dtype='float')
    tempout[proclocs, :] = invtransformeddata[:, :]
    tide_io.savetonifti(tempout.reshape((xsize, ysize, numslices, invtransformeddata.shape[1])), datafile_hdr,
                        outputrootname + '_fit')
