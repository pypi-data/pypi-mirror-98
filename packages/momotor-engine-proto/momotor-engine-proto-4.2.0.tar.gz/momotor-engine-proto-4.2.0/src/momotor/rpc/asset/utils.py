import asyncio
import pathlib
import typing

from asyncio_extras import open_async

from momotor.rpc.const import CHUNK_SIZE, MAX_IDENTITY_LENGTH
from momotor.rpc.hash import new as new_hash, encode as encode_hash, encode_content
from momotor.rpc.proto.auth_pb2 import ServerInfoResponse


def get_file_multihash(path: typing.Union[str, pathlib.Path], server_info: ServerInfoResponse = None) \
        -> typing.Tuple[bytes, bool]:
    """ Get multihash value for file in `path`

    If the file is small enough to fit, the entire contents will be encoded in the multihash instead of an actual
    hash. A boolean in the result will indicate whether the result is a real hash or encoded content

    If a `server_info` object is provided, the resulting hash will be compatible with the server, otherwise
    the hash generated will use the capabilities of the local system.

    :param path: path to file
    :param server_info: Remote server's info
    :return: tuple of base58 encoded multihash, and boolean indicating if identity encoding was used
    """
    path = pathlib.Path(path)
    size = path.stat().st_size

    if server_info:
        max_identity_length = min(server_info.maxIdHashLen or 0, MAX_IDENTITY_LENGTH)
        supported_funcs = server_info.hashFunc
        chunk_size = min(server_info.chunkSize, CHUNK_SIZE)
    else:
        max_identity_length = MAX_IDENTITY_LENGTH
        supported_funcs = None
        chunk_size = CHUNK_SIZE

    if size <= max_identity_length:
        with path.open('rb') as f:
            chunk = f.read(size)

        return encode_content(chunk, use_identity=True), True

    hash_func = new_hash(supported_funcs=supported_funcs)
    with path.open('rb') as f:
        while True:
            chunk = f.read(chunk_size)
            if not chunk:
                break

            hash_func.update(chunk)

    return encode_hash(hash_func), False


def get_file_hash(func_code: typing.Union[str, int], path: typing.Union[str, pathlib.Path]) -> bytes:
    """ Calculate a hash of the given file's content

    :param func_code: a multihash code (string or integer)
    :param path: path of the file to hash
    :return: unencoded hash digest generated by the hash function
    """
    hash_func = new_hash(func_code=func_code)

    with pathlib.Path(path).open('rb') as f:
        while True:
            content = f.read(CHUNK_SIZE)
            if content:
                hash_func.update(content)
            else:
                break

    return hash_func.digest()


async def file_reader(path: pathlib.Path, mode: str, queue: asyncio.Queue, *, chunk_size: int = CHUNK_SIZE):
    """ Helper to read chunks from a file into a queue

    :param path: file to read
    :param mode: file read mode
    :param queue: queue to put the chunks into. Should be a one-place queue
    :param chunk_size: maximum size of the chunks
    """
    try:
        async with open_async(path, mode) as f:
            # noinspection PyTypeChecker
            async for chunk in f.async_readchunks(chunk_size):
                await queue.put(chunk)

    finally:
        await queue.put(None)


async def file_writer(path: pathlib.Path, mode: str, queue: asyncio.Queue):
    """ Helper to write chunks from a queue into a file

    :param path: file to write
    :param mode: file write mode
    :param queue: queue to get the chunks from. Should be a one-place queue
    """
    async with open_async(path, mode) as f:
        while True:
            chunk = await queue.get()
            if chunk is None:
                return

            await f.write(chunk)
