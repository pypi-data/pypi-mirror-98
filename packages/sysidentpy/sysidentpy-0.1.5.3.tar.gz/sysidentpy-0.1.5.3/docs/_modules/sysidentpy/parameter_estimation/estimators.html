
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>sysidentpy.parameter_estimation.estimators &#8212; NARMAX models</title>
    
  <link rel="stylesheet" href="../../../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../../../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../../../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/sphinx-book-theme.37f24b989f4638ff9c27c22dc7559d4f.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    
  <link rel="preload" as="script" href="../../../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/togglebutton.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../_static/sphinx-book-theme.7d483ff0a819d6edff12ce0b1ead3928.js"></script>
    <link rel="canonical" href="http://sysidentpy.org/_modules/sysidentpy/parameter_estimation/estimators.html" />
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />


<!-- Opengraph tags -->
<meta property="og:url"         content="http://sysidentpy.org/_modules/sysidentpy/parameter_estimation/estimators.html" />
<meta property="og:type"        content="article" />
<meta property="og:title"       content="NARMAX models" />
<meta property="og:description" content="" />
<meta property="og:image"       content="http://sysidentpy.org/_static/sysidentpy-logo.png" />

<meta name="twitter:card" content="summary" />


  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../../index.html">
  
  <img src="../../../_static/sysidentpy-logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">NARMAX models</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../installation.html">
   Install Guide
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../introduction_to_narmax.html">
   A brief introduction to NARMAX models.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../user_guide.html">
   User Guide
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../dev_guide.html">
   Contributing
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../../notebooks.html">
   Jupyter notebooks
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../../examples/basic_steps.html">
     Presenting main functionality
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../examples/multiple_inputs_example.html">
     Multiple Inputs usage
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../examples/information_criteria_examples.html">
     Information Criteria - Examples
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../examples/extended_least_squares.html">
     Important notes and examples of how to use Extended Least Squares
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../examples/defining_lags.html">
     Setting specific lags
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../examples/parameter_estimation.html">
     Parameter Estimation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../examples/f_16_benchmark.html">
     Example: F-16 Ground Vibration Test benchmark
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../examples/narx_neural_network.html">
     Building NARX Neural Network using Sysidentpy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../examples/general_estimators.html">
     Building NARX models using general estimators
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../examples/simulating_a_predefined_model.html">
     Simulate a Predefined Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../examples/system_identification_using_adaptative_filters.html">
     System Identification Using Adaptative Filters
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../examples/identification_of_an_electromechanical_system.html">
     Identification of an electromechanical system
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../examples/n_steps_ahead_prediction.html">
     Example: N-steps-ahead prediction - F-16 Ground Vibration Test benchmark
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../changelog/v0.1.5.html">
   Changes in SysIdentPy
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../../code.html">
   Codes
  </a>
  <ul class="simple collapse-ul">
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../code.html#module-sysidentpy.base">
   sysidentpy base
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../code.html#sysidentpy-narmax">
   sysidentpy narmax
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../code.html#sysidentpy-simulation">
   sysidentpy simulation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../code.html#sysidentpy-narx-neural-network">
   sysidentpy narx_neural_network
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../code.html#sysidentpy-general-estimators">
   sysidentpy general_estimators
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../code.html#module-sysidentpy.residues.residues_correlation">
   sysidentpy residues
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../code.html#module-sysidentpy.metrics._regression">
   sysidentpy metrics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../code.html#module-sysidentpy.parameter_estimation.estimators">
   sysidentpy estimators
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../code.html#module-sysidentpy.utils._check_arrays">
   sysidentpy utils
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../code.html#module-sysidentpy.utils.generate_data">
   sysidentpy generate data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../code.html#indices-and-tables">
   Indices and tables
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/wilsonrljr/sysidentpy/"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/wilsonrljr/sysidentpy//issues/new?title=Issue%20on%20page%20%2F_modules/sysidentpy/parameter_estimation/estimators.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>


            <!-- Full screen (wrap in <a> to have style consistency -->
            <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                    data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                    title="Fullscreen mode"><i
                        class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <h1>Source code for sysidentpy.parameter_estimation.estimators</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot; Least Squares Methodos for parameter estimation &quot;&quot;&quot;</span>

<span class="c1"># Authors:</span>
<span class="c1">#           Wilson Rocha Lacerda Junior &lt;wilsonrljr@outlook.com&gt;</span>
<span class="c1"># License: BSD 3 clause</span>


<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">warnings</span>

<span class="c1"># from ..base import InformationMatrix</span>


<div class="viewcode-block" id="Estimators"><a class="viewcode-back" href="../../../code.html#sysidentpy.parameter_estimation.estimators.Estimators">[docs]</a><span class="k">class</span> <span class="nc">Estimators</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Oridanry Least squares for linear parameter estimation&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">aux_lag</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">lam</span><span class="o">=</span><span class="mf">0.98</span><span class="p">,</span>
        <span class="n">delta</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
        <span class="n">offset_covariance</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
        <span class="n">mu</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
        <span class="n">eps</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float</span><span class="p">)</span><span class="o">.</span><span class="n">eps</span><span class="p">,</span>
        <span class="n">gama</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
        <span class="n">weight</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span>
    <span class="p">):</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_eps</span> <span class="o">=</span> <span class="n">eps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_mu</span> <span class="o">=</span> <span class="n">mu</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_offset_covariance</span> <span class="o">=</span> <span class="n">offset_covariance</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_aux_lag</span> <span class="o">=</span> <span class="n">aux_lag</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_lam</span> <span class="o">=</span> <span class="n">lam</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_delta</span> <span class="o">=</span> <span class="n">delta</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_gama</span> <span class="o">=</span> <span class="n">gama</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_weight</span> <span class="o">=</span> <span class="n">weight</span>  <span class="c1"># &lt;0  e &lt;1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_validate_params</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_validate_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Validate input params.&quot;&quot;&quot;</span>
        <span class="n">attributes</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;aux_lag&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_aux_lag</span><span class="p">,</span>
            <span class="s2">&quot;lam&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lam</span><span class="p">,</span>
            <span class="s2">&quot;delta&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_delta</span><span class="p">,</span>
            <span class="s2">&quot;offset_covariance&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_offset_covariance</span><span class="p">,</span>
            <span class="s2">&quot;mu&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mu</span><span class="p">,</span>
            <span class="s2">&quot;eps&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_eps</span><span class="p">,</span>
            <span class="s2">&quot;gama&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_gama</span><span class="p">,</span>
            <span class="s2">&quot;weight&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weight</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="k">for</span> <span class="n">attribute</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">attributes</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">integer</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">)):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">attribute</span><span class="si">}</span><span class="s2"> must be int or float (positive).&quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;Got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">attribute</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="p">)</span>
                <span class="p">)</span>

            <span class="k">if</span> <span class="n">attribute</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;lam&quot;</span><span class="p">,</span> <span class="s2">&quot;weight&quot;</span><span class="p">,</span> <span class="s2">&quot;offset_covariance&quot;</span><span class="p">]:</span>
                <span class="k">if</span> <span class="n">value</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">or</span> <span class="n">value</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">attribute</span><span class="si">}</span><span class="s2"> must lies on [0 1] range. Got </span><span class="si">{</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="p">)</span>

            <span class="k">if</span> <span class="n">value</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">attribute</span><span class="si">}</span><span class="s2"> must be positive. Got </span><span class="si">{</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;Check the documentation for allowed values&quot;</span>
                    <span class="p">)</span>
                <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_check_linear_dependence_rows</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">psi</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">matrix_rank</span><span class="p">(</span><span class="n">psi</span><span class="p">)</span> <span class="o">!=</span> <span class="n">psi</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="p">(</span>
                    <span class="s2">&quot;Psi matrix might have linearly dependent rows.&quot;</span>
                    <span class="s2">&quot;Be careful and check your data&quot;</span>
                <span class="p">),</span>
                <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
            <span class="p">)</span>

<div class="viewcode-block" id="Estimators.least_squares"><a class="viewcode-back" href="../../../code.html#sysidentpy.parameter_estimation.estimators.Estimators.least_squares">[docs]</a>    <span class="k">def</span> <span class="nf">least_squares</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">psi</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Estimate the model parameters using Least Squares method.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        psi : ndarray of floats</span>
<span class="sd">            The information matrix of the model.</span>
<span class="sd">        y_train : array-like of shape = y_training</span>
<span class="sd">            The data used to training the model.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        theta : array-like of shape = number_of_model_elements</span>
<span class="sd">            The estimated parameters of the model.</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>
<span class="sd">        [1] Manuscript: Sorenson, H. W. (1970). Least-squares estimation:</span>
<span class="sd">            from Gauss to Kalman. IEEE spectrum, 7(7), 63-68.</span>
<span class="sd">            http://pzs.dstu.dp.ua/DataMining/mls/bibl/Gauss2Kalman.pdf</span>
<span class="sd">        [2] Book (Portuguese): Aguirre, L. A. (2007). Introduçaoa identificaçao</span>
<span class="sd">            de sistemas: técnicas lineares enao-lineares aplicadas a sistemas</span>
<span class="sd">            reais. Editora da UFMG. 3a ediçao.</span>
<span class="sd">        [3] Manuscript: Markovsky, I., &amp; Van Huffel, S. (2007).</span>
<span class="sd">            Overview of total least-squares methods.</span>
<span class="sd">            Signal processing, 87(10), 2283-2302.</span>
<span class="sd">            https://eprints.soton.ac.uk/263855/1/tls_overview.pdf</span>
<span class="sd">        [4] Wikipedia entry on Least Squares</span>
<span class="sd">            https://en.wikipedia.org/wiki/Least_squares</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_linear_dependence_rows</span><span class="p">(</span><span class="n">psi</span><span class="p">)</span>

        <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_aux_lag</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">theta</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">pinv</span><span class="p">(</span><span class="n">psi</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">psi</span><span class="p">))</span> <span class="o">@</span> <span class="n">psi</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">y</span>
        <span class="k">return</span> <span class="n">theta</span></div>

<div class="viewcode-block" id="Estimators.total_least_squares"><a class="viewcode-back" href="../../../code.html#sysidentpy.parameter_estimation.estimators.Estimators.total_least_squares">[docs]</a>    <span class="k">def</span> <span class="nf">total_least_squares</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">psi</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Estimate the model parameters using Total Least Squares method.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        psi : ndarray of floats</span>
<span class="sd">            The information matrix of the model.</span>
<span class="sd">        y_train : array-like of shape = y_training</span>
<span class="sd">            The data used to training the model.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        theta : array-like of shape = number_of_model_elements</span>
<span class="sd">            The estimated parameters of the model.</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>
<span class="sd">        [1] Manuscript: Golub, G. H., &amp; Van Loan, C. F. (1980).</span>
<span class="sd">            An analysis of the total least squares problem.</span>
<span class="sd">            SIAM journal on numerical analysis, 17(6), 883-893.</span>
<span class="sd">        [2] Manuscript: Markovsky, I., &amp; Van Huffel, S. (2007).</span>
<span class="sd">            Overview of total least-squares methods.</span>
<span class="sd">            Signal processing, 87(10), 2283-2302.</span>
<span class="sd">            https://eprints.soton.ac.uk/263855/1/tls_overview.pdf</span>
<span class="sd">        [3] Wikipedia entry on Total Least Squares</span>
<span class="sd">            https://en.wikipedia.org/wiki/Total_least_squares</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_aux_lag</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">full</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">psi</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
        <span class="n">n</span> <span class="o">=</span> <span class="n">psi</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">u</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">full</span><span class="p">,</span> <span class="n">full_matrices</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">theta</span> <span class="o">=</span> <span class="o">-</span><span class="n">v</span><span class="o">.</span><span class="n">T</span><span class="p">[:</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">:]</span> <span class="o">/</span> <span class="n">v</span><span class="o">.</span><span class="n">T</span><span class="p">[</span><span class="n">n</span><span class="p">:,</span> <span class="n">n</span><span class="p">:]</span>
        <span class="k">return</span> <span class="n">theta</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_initial_values</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">psi</span><span class="p">):</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_aux_lag</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">n_theta</span> <span class="o">=</span> <span class="n">psi</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">psi</span><span class="p">)</span>
        <span class="n">theta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">n_theta</span><span class="p">,</span> <span class="n">n</span><span class="p">])</span>
        <span class="n">xi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">y</span><span class="p">,</span> <span class="n">n_theta</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">xi</span>

<div class="viewcode-block" id="Estimators.recursive_least_squares"><a class="viewcode-back" href="../../../code.html#sysidentpy.parameter_estimation.estimators.Estimators.recursive_least_squares">[docs]</a>    <span class="k">def</span> <span class="nf">recursive_least_squares</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">psi</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Estimate the model parameters using the Recursive Least Squares method.</span>

<span class="sd">        The implementation consider the forgeting factor.</span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        psi : ndarray of floats</span>
<span class="sd">            The information matrix of the model.</span>
<span class="sd">        y_train : array-like of shape = y_training</span>
<span class="sd">            The data used to training the model.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        theta : array-like of shape = number_of_model_elements</span>
<span class="sd">            The estimated parameters of the model.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        A more in-depth documentation of all methods for parameters estimation</span>
<span class="sd">        will be available soon. For now, please refer to the mentioned</span>
<span class="sd">        references.</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>
<span class="sd">        [1] Book (Portuguese): Aguirre, L. A. (2007). Introduçaoa identificaçao</span>
<span class="sd">            de sistemas: técnicas lineares enao-lineares aplicadas a sistemas</span>
<span class="sd">            reais. Editora da UFMG. 3a ediçao.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">y</span><span class="p">,</span> <span class="n">n_theta</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">xi</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initial_values</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">psi</span><span class="p">)</span>

        <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n_theta</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">_delta</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
            <span class="n">psi_tmp</span> <span class="o">=</span> <span class="n">psi</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">k_numerator</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lam</span> <span class="o">**</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">p</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">psi_tmp</span><span class="p">)</span>
            <span class="n">k_denominator</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lam</span> <span class="o">**</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">psi_tmp</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">p</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">psi_tmp</span><span class="p">)</span>
            <span class="n">k</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="n">k_numerator</span><span class="p">,</span> <span class="n">k_denominator</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">xi</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">psi_tmp</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">theta</span><span class="p">[:,</span> <span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
            <span class="n">theta</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">theta</span><span class="p">[:,</span> <span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">k</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xi</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]))</span>

            <span class="n">p1</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">psi</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">psi</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
            <span class="n">p2</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">psi</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">p</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">psi</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
                <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lam</span>
            <span class="p">)</span>

            <span class="n">p_numerator</span> <span class="o">=</span> <span class="n">p</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="n">p1</span><span class="p">,</span> <span class="n">p2</span><span class="p">)</span>
            <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="n">p_numerator</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lam</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">theta_evolution</span> <span class="o">=</span> <span class="n">theta</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">theta</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span></div>

<div class="viewcode-block" id="Estimators.affine_least_mean_squares"><a class="viewcode-back" href="../../../code.html#sysidentpy.parameter_estimation.estimators.Estimators.affine_least_mean_squares">[docs]</a>    <span class="k">def</span> <span class="nf">affine_least_mean_squares</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">psi</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Estimate the model parameters using the Affine Least Mean Squares.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        psi : ndarray of floats</span>
<span class="sd">            The information matrix of the model.</span>
<span class="sd">        y_train : array-like of shape = y_training</span>
<span class="sd">            The data used to training the model.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        theta : array-like of shape = number_of_model_elements</span>
<span class="sd">            The estimated parameters of the model.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        A more in-depth documentation of all methods for parameters estimation</span>
<span class="sd">        will be available soon. For now, please refer to the mentioned</span>
<span class="sd">        references.</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>
<span class="sd">        [1] Book: Poularikas, A. D. (2017). Adaptive filtering: Fundamentals</span>
<span class="sd">            of least mean squares with MATLAB®. CRC Press.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">y</span><span class="p">,</span> <span class="n">n_theta</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">xi</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initial_values</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">psi</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_theta</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">xi</span> <span class="o">=</span> <span class="n">y</span> <span class="o">-</span> <span class="n">psi</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">theta</span><span class="p">[:,</span> <span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
            <span class="n">aux</span> <span class="o">=</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_mu</span>
                <span class="o">*</span> <span class="n">psi</span>
<div class="viewcode-block" id="Estimators.least_mean_squares"><a class="viewcode-back" href="../../../code.html#sysidentpy.parameter_estimation.estimators.Estimators.least_mean_squares">[docs]</a>                <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">pinv</span><span class="p">(</span>
                    <span class="n">psi</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">psi</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_offset_covariance</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n_theta</span><span class="p">)</span>
                <span class="p">)</span>
            <span class="p">)</span>
            <span class="n">theta</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">theta</span><span class="p">[:,</span> <span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">aux</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xi</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">theta</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">least_mean_squares</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">psi</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Estimate the model parameters using the Least Mean Squares filter.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        psi : ndarray of floats</span>
<span class="sd">            The information matrix of the model.</span>
<span class="sd">        y_train : array-like of shape = y_training</span>
<span class="sd">            The data used to training the model.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        theta : array-like of shape = number_of_model_elements</span>
<span class="sd">            The estimated parameters of the model.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        A more in-depth documentation of all methods for parameters estimation</span>
<span class="sd">        will be available soon. For now, please refer to the mentioned</span>
<span class="sd">        references.</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>
<span class="sd">        [1] Book: Haykin, S., &amp; Widrow, B. (Eds.). (2003). Least-mean-square</span>
<span class="sd">            adaptive filters (Vol. 31). John Wiley &amp; Sons.</span>
<span class="sd">        [2] Dissertation (Portuguese): Zipf, J. G. F. (2011). Classificação,</span>
<span class="sd">            análise estatística e novas estratégias de algoritmos LMS de passo</span>
<span class="sd">            variável.</span>
<span class="sd">        [3] Wikipedia entry on Least Mean Squares</span>
<span class="sd">            https://en.wikipedia.org/wiki/Least_mean_squares_filter</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">y</span><span class="p">,</span> <span class="n">n_theta</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">xi</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initial_values</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">psi</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_theta</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
            <span class="n">psi_tmp</span> <span class="o">=</span> <span class="n">psi</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">xi</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">psi_tmp</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">theta</span><span class="p">[:,</span> <span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
            <span class="n">theta</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span>
                <span class="n">theta</span><span class="p">[:,</span> <span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mu</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">xi</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">psi_tmp</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="n">theta</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span></div>

<div class="viewcode-block" id="Estimators.least_mean_squares_sign_error"><a class="viewcode-back" href="../../../code.html#sysidentpy.parameter_estimation.estimators.Estimators.least_mean_squares_sign_error">[docs]</a>    <span class="k">def</span> <span class="nf">least_mean_squares_sign_error</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">psi</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Parameter estimation using the Sign-Error  Least Mean Squares filter.</span>

<span class="sd">        The sign-error LMS algorithm uses the sign of the error vector</span>
<span class="sd">        to change the filter coefficients.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        psi : ndarray of floats</span>
<span class="sd">            The information matrix of the model.</span>
<span class="sd">        y_train : array-like of shape = y_training</span>
<span class="sd">            The data used to training the model.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        theta : array-like of shape = number_of_model_elements</span>
<span class="sd">            The estimated parameters of the model.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        A more in-depth documentation of all methods for parameters estimation</span>
<span class="sd">        will be available soon. For now, please refer to the mentioned</span>
<span class="sd">        references.</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>
<span class="sd">        [1]`Book: Hayes, M. H. (2009). Statistical digital signal processing</span>
<span class="sd">            and modeling. John Wiley &amp; Sons.</span>
<span class="sd">        [2]`Dissertation (Portuguese): Zipf, J. G. F. (2011). Classificação,</span>
<span class="sd">            análise estatística e novas estratégias de algoritmos LMS de passo</span>
<span class="sd">            variável.</span>
<span class="sd">        [3] Wikipedia entry on Least Mean Squares</span>
<span class="sd">            https://en.wikipedia.org/wiki/Least_mean_squares_filter</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">y</span><span class="p">,</span> <span class="n">n_theta</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">xi</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initial_values</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">psi</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_theta</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
            <span class="n">psi_tmp</span> <span class="o">=</span> <span class="n">psi</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">xi</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">psi_tmp</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">theta</span><span class="p">[:,</span> <span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
            <span class="n">theta</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span>
                <span class="n">theta</span><span class="p">[:,</span> <span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mu</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xi</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span> <span class="o">*</span> <span class="n">psi_tmp</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="n">theta</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span></div>

<div class="viewcode-block" id="Estimators.normalized_least_mean_squares"><a class="viewcode-back" href="../../../code.html#sysidentpy.parameter_estimation.estimators.Estimators.normalized_least_mean_squares">[docs]</a>    <span class="k">def</span> <span class="nf">normalized_least_mean_squares</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">psi</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Parameter estimation using the Normalized Least Mean Squares filter.</span>

<span class="sd">        The normalization is used to avoid numerical instability when updating</span>
<span class="sd">        the estimated parameters.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        psi : ndarray of floats</span>
<span class="sd">            The information matrix of the model.</span>
<span class="sd">        y_train : array-like of shape = y_training</span>
<span class="sd">            The data used to training the model.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        theta : array-like of shape = number_of_model_elements</span>
<span class="sd">            The estimated parameters of the model.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        A more in-depth documentation of all methods for parameters estimation</span>
<span class="sd">        will be available soon. For now, please refer to the mentioned</span>
<span class="sd">        references.</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>
<span class="sd">        [1]`Book: Hayes, M. H. (2009). Statistical digital signal processing</span>
<span class="sd">            and modeling. John Wiley &amp; Sons.</span>
<span class="sd">        [2] Dissertation (Portuguese): Zipf, J. G. F. (2011). Classificação,</span>
<span class="sd">            análise estatística e novas estratégias de algoritmos LMS de passo</span>
<span class="sd">            variável.</span>
<span class="sd">        [3] Wikipedia entry on Least Mean Squares</span>
<span class="sd">            https://en.wikipedia.org/wiki/Least_mean_squares_filter</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">y</span><span class="p">,</span> <span class="n">n_theta</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">xi</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initial_values</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">psi</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_theta</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
            <span class="n">psi_tmp</span> <span class="o">=</span> <span class="n">psi</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">xi</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">psi_tmp</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">theta</span><span class="p">[:,</span> <span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
            <span class="n">theta</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span>
                <span class="n">theta</span><span class="p">[:,</span> <span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                <span class="o">+</span> <span class="mi">2</span>
                <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mu</span>
                <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">xi</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
                <span class="o">*</span> <span class="p">(</span><span class="n">psi_tmp</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_eps</span> <span class="o">+</span> <span class="n">psi_tmp</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">psi_tmp</span><span class="p">))</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="n">theta</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span></div>

<div class="viewcode-block" id="Estimators.least_mean_squares_normalized_sign_error"><a class="viewcode-back" href="../../../code.html#sysidentpy.parameter_estimation.estimators.Estimators.least_mean_squares_normalized_sign_error">[docs]</a>    <span class="k">def</span> <span class="nf">least_mean_squares_normalized_sign_error</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">psi</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Parameter estimation using the Normalized Sign-Error LMS filter.</span>

<span class="sd">        The normalization is used to avoid numerical instability when updating</span>
<span class="sd">        the estimated parameters and the sign of the error vector is used to</span>
<span class="sd">        to change the filter coefficients.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        psi : ndarray of floats</span>
<span class="sd">            The information matrix of the model.</span>
<span class="sd">        y_train : array-like of shape = y_training</span>
<span class="sd">            The data used to training the model.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        theta : array-like of shape = number_of_model_elements</span>
<span class="sd">            The estimated parameters of the model.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        A more in-depth documentation of all methods for parameters estimation</span>
<span class="sd">        will be available soon. For now, please refer to the mentioned</span>
<span class="sd">        references.</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>
<span class="sd">        [1] Book: Hayes, M. H. (2009). Statistical digital signal processing</span>
<span class="sd">            and modeling. John Wiley &amp; Sons.</span>
<span class="sd">        [2] Dissertation (Portuguese): Zipf, J. G. F. (2011). Classificação,</span>
<span class="sd">            análise estatística e novas estratégias de algoritmos LMS de passo</span>
<span class="sd">            variável.</span>
<span class="sd">        [3] Wikipedia entry on Least Mean Squares</span>
<span class="sd">            https://en.wikipedia.org/wiki/Least_mean_squares_filter</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">y</span><span class="p">,</span> <span class="n">n_theta</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">xi</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initial_values</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">psi</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_theta</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
            <span class="n">psi_tmp</span> <span class="o">=</span> <span class="n">psi</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">xi</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">psi_tmp</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">theta</span><span class="p">[:,</span> <span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
            <span class="n">theta</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span>
                <span class="n">theta</span><span class="p">[:,</span> <span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                <span class="o">+</span> <span class="mi">2</span>
                <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mu</span>
                <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xi</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
                <span class="o">*</span> <span class="p">(</span><span class="n">psi_tmp</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_eps</span> <span class="o">+</span> <span class="n">psi_tmp</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">psi_tmp</span><span class="p">))</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="n">theta</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span></div>

<div class="viewcode-block" id="Estimators.least_mean_squares_sign_regressor"><a class="viewcode-back" href="../../../code.html#sysidentpy.parameter_estimation.estimators.Estimators.least_mean_squares_sign_regressor">[docs]</a>    <span class="k">def</span> <span class="nf">least_mean_squares_sign_regressor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">psi</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Parameter estimation using the  Sign-Regressor LMS filter.</span>

<span class="sd">        The sign-regressor LMS algorithm uses the sign of the matrix</span>
<span class="sd">        information to change the filter coefficients.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        psi : ndarray of floats</span>
<span class="sd">            The information matrix of the model.</span>
<span class="sd">        y_train : array-like of shape = y_training</span>
<span class="sd">            The data used to training the model.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        theta : array-like of shape = number_of_model_elements</span>
<span class="sd">            The estimated parameters of the model.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        A more in-depth documentation of all methods for parameters estimation</span>
<span class="sd">        will be available soon. For now, please refer to the mentioned</span>
<span class="sd">        references.</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>
<span class="sd">        [1] Book: Hayes, M. H. (2009). Statistical digital signal processing</span>
<span class="sd">            and modeling. John Wiley &amp; Sons.</span>
<span class="sd">        [2] Dissertation (Portuguese): Zipf, J. G. F. (2011). Classificação,</span>
<span class="sd">            análise estatística e novas estratégias de algoritmos LMS de passo</span>
<span class="sd">            variável.</span>
<span class="sd">        [3] Wikipedia entry on Least Mean Squares</span>
<span class="sd">            https://en.wikipedia.org/wiki/Least_mean_squares_filter</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">y</span><span class="p">,</span> <span class="n">n_theta</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">xi</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initial_values</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">psi</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_theta</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
            <span class="n">psi_tmp</span> <span class="o">=</span> <span class="n">psi</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">xi</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">psi_tmp</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">theta</span><span class="p">[:,</span> <span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
            <span class="n">theta</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span>
                <span class="n">theta</span><span class="p">[:,</span> <span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mu</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">xi</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">psi_tmp</span><span class="p">)</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="n">theta</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span></div>

<div class="viewcode-block" id="Estimators.least_mean_squares_normalized_sign_regressor"><a class="viewcode-back" href="../../../code.html#sysidentpy.parameter_estimation.estimators.Estimators.least_mean_squares_normalized_sign_regressor">[docs]</a>    <span class="k">def</span> <span class="nf">least_mean_squares_normalized_sign_regressor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">psi</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Parameter estimation using the Normalized Sign-Regressor LMS filter.</span>

<span class="sd">        The normalization is used to avoid numerical instability when updating</span>
<span class="sd">        the estimated parameters and the sign of the information matrix is</span>
<span class="sd">        used to change the filter coefficients.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        psi : ndarray of floats</span>
<span class="sd">            The information matrix of the model.</span>
<span class="sd">        y_train : array-like of shape = y_training</span>
<span class="sd">            The data used to training the model.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        theta : array-like of shape = number_of_model_elements</span>
<span class="sd">            The estimated parameters of the model.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        A more in-depth documentation of all methods for parameters estimation</span>
<span class="sd">        will be available soon. For now, please refer to the mentioned</span>
<span class="sd">        references.</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>
<span class="sd">        [1] Book: Hayes, M. H. (2009). Statistical digital signal processing</span>
<span class="sd">            and modeling. John Wiley &amp; Sons.</span>
<span class="sd">        [2] Dissertation (Portuguese): Zipf, J. G. F. (2011). Classificação,</span>
<span class="sd">            análise estatística e novas estratégias de algoritmos LMS de passo</span>
<span class="sd">            variável.</span>
<span class="sd">        [3] Wikipedia entry on Least Mean Squares</span>
<span class="sd">            https://en.wikipedia.org/wiki/Least_mean_squares_filter</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">y</span><span class="p">,</span> <span class="n">n_theta</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">xi</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initial_values</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">psi</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_theta</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
            <span class="n">psi_tmp</span> <span class="o">=</span> <span class="n">psi</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">xi</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">psi_tmp</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">theta</span><span class="p">[:,</span> <span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
            <span class="n">theta</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span>
                <span class="n">theta</span><span class="p">[:,</span> <span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mu</span>
                <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">xi</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
                <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">psi_tmp</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_eps</span> <span class="o">+</span> <span class="n">psi_tmp</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">psi_tmp</span><span class="p">))</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="n">theta</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span></div>

<div class="viewcode-block" id="Estimators.least_mean_squares_sign_sign"><a class="viewcode-back" href="../../../code.html#sysidentpy.parameter_estimation.estimators.Estimators.least_mean_squares_sign_sign">[docs]</a>    <span class="k">def</span> <span class="nf">least_mean_squares_sign_sign</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">psi</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Parameter estimation using the  Sign-Sign LMS filter.</span>

<span class="sd">        The sign-regressor LMS algorithm uses both the sign of the matrix</span>
<span class="sd">        information and the sign of the error vector to change the filter</span>
<span class="sd">        coefficients.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        psi : ndarray of floats</span>
<span class="sd">            The information matrix of the model.</span>
<span class="sd">        y_train : array-like of shape = y_training</span>
<span class="sd">            The data used to training the model.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        theta : array-like of shape = number_of_model_elements</span>
<span class="sd">            The estimated parameters of the model.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        A more in-depth documentation of all methods for parameters estimation</span>
<span class="sd">        will be available soon. For now, please refer to the mentioned</span>
<span class="sd">        references.</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>
<span class="sd">        [1] Book: Hayes, M. H. (2009). Statistical digital signal processing</span>
<span class="sd">            and modeling. John Wiley &amp; Sons.</span>
<span class="sd">        [2] Dissertation (Portuguese): Zipf, J. G. F. (2011). Classificação,</span>
<span class="sd">            análise estatística e novas estratégias de algoritmos LMS de passo</span>
<span class="sd">            variável.</span>
<span class="sd">        [3] Wikipedia entry on Least Mean Squares</span>
<span class="sd">            https://en.wikipedia.org/wiki/Least_mean_squares_filter</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">y</span><span class="p">,</span> <span class="n">n_theta</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">xi</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initial_values</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">psi</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_theta</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
            <span class="n">psi_tmp</span> <span class="o">=</span> <span class="n">psi</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">xi</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">psi_tmp</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">theta</span><span class="p">[:,</span> <span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
            <span class="n">theta</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span>
                <span class="n">theta</span><span class="p">[:,</span> <span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mu</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xi</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">psi_tmp</span><span class="p">)</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="n">theta</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span></div>

<div class="viewcode-block" id="Estimators.least_mean_squares_normalized_sign_sign"><a class="viewcode-back" href="../../../code.html#sysidentpy.parameter_estimation.estimators.Estimators.least_mean_squares_normalized_sign_sign">[docs]</a>    <span class="k">def</span> <span class="nf">least_mean_squares_normalized_sign_sign</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">psi</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Parameter estimation using the Normalized Sign-Sign LMS filter.</span>

<span class="sd">        The normalization is used to avoid numerical instability when updating</span>
<span class="sd">        the estimated parameters and both the sign of the information matrix</span>
<span class="sd">        and the sign of the error vector are used to change the filter</span>
<span class="sd">        coefficients.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        psi : ndarray of floats</span>
<span class="sd">            The information matrix of the model.</span>
<span class="sd">        y_train : array-like of shape = y_training</span>
<span class="sd">            The data used to training the model.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        theta : array-like of shape = number_of_model_elements</span>
<span class="sd">            The estimated parameters of the model.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        A more in-depth documentation of all methods for parameters estimation</span>
<span class="sd">        will be available soon. For now, please refer to the mentioned</span>
<span class="sd">        references.</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>
<span class="sd">        [1] Book: Hayes, M. H. (2009). Statistical digital signal processing</span>
<span class="sd">            and modeling. John Wiley &amp; Sons.</span>
<span class="sd">        [2] Dissertation (Portuguese): Zipf, J. G. F. (2011). Classificação,</span>
<span class="sd">            análise estatística e novas estratégias de algoritmos LMS de passo</span>
<span class="sd">            variável.</span>
<span class="sd">        [3] Wikipedia entry on Least Mean Squares</span>
<span class="sd">            https://en.wikipedia.org/wiki/Least_mean_squares_filter</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">y</span><span class="p">,</span> <span class="n">n_theta</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">xi</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initial_values</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">psi</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_theta</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
            <span class="n">psi_tmp</span> <span class="o">=</span> <span class="n">psi</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">xi</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">psi_tmp</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">theta</span><span class="p">[:,</span> <span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
            <span class="n">theta</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span>
                <span class="n">theta</span><span class="p">[:,</span> <span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                <span class="o">+</span> <span class="mi">2</span>
                <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mu</span>
                <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xi</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
                <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">psi_tmp</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_eps</span> <span class="o">+</span> <span class="n">psi_tmp</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">psi_tmp</span><span class="p">))</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="n">theta</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span></div>

<div class="viewcode-block" id="Estimators.least_mean_squares_normalized_leaky"><a class="viewcode-back" href="../../../code.html#sysidentpy.parameter_estimation.estimators.Estimators.least_mean_squares_normalized_leaky">[docs]</a>    <span class="k">def</span> <span class="nf">least_mean_squares_normalized_leaky</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">psi</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Parameter estimation using the  Normalized Leaky LMS filter.</span>

<span class="sd">        When the leakage factor, gama, is set to 0 then there is no</span>
<span class="sd">        leakage in the estimation process.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        psi : ndarray of floats</span>
<span class="sd">            The information matrix of the model.</span>
<span class="sd">        y_train : array-like of shape = y_training</span>
<span class="sd">            The data used to training the model.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        theta : array-like of shape = number_of_model_elements</span>
<span class="sd">            The estimated parameters of the model.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        A more in-depth documentation of all methods for parameters estimation</span>
<span class="sd">        will be available soon. For now, please refer to the mentioned</span>
<span class="sd">        references.</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>
<span class="sd">        [1] Book: Hayes, M. H. (2009). Statistical digital signal processing</span>
<span class="sd">            and modeling. John Wiley &amp; Sons.</span>
<span class="sd">        [2] Dissertation (Portuguese): Zipf, J. G. F. (2011). Classificação,</span>
<span class="sd">            análise estatística e novas estratégias de algoritmos LMS de passo</span>
<span class="sd">            variável.</span>
<span class="sd">        [3] Wikipedia entry on Least Mean Squares</span>
<span class="sd">            https://en.wikipedia.org/wiki/Least_mean_squares_filter</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">y</span><span class="p">,</span> <span class="n">n_theta</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">xi</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initial_values</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">psi</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_theta</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
            <span class="n">psi_tmp</span> <span class="o">=</span> <span class="n">psi</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">xi</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">psi_tmp</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">theta</span><span class="p">[:,</span> <span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
            <span class="n">theta</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span>
                <span class="n">theta</span><span class="p">[:,</span> <span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mu</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_gama</span><span class="p">)</span>
                <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mu</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">xi</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">psi_tmp</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_eps</span> <span class="o">+</span> <span class="n">psi_tmp</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">psi_tmp</span><span class="p">)</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="n">theta</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span></div>

<div class="viewcode-block" id="Estimators.least_mean_squares_leaky"><a class="viewcode-back" href="../../../code.html#sysidentpy.parameter_estimation.estimators.Estimators.least_mean_squares_leaky">[docs]</a>    <span class="k">def</span> <span class="nf">least_mean_squares_leaky</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">psi</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Parameter estimation using the  Leaky LMS filter.</span>

<span class="sd">        When the leakage factor, gama, is set to 0 then there is no</span>
<span class="sd">        leakage in the estimation process.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        psi : ndarray of floats</span>
<span class="sd">            The information matrix of the model.</span>
<span class="sd">        y_train : array-like of shape = y_training</span>
<span class="sd">            The data used to training the model.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        theta : array-like of shape = number_of_model_elements</span>
<span class="sd">            The estimated parameters of the model.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        A more in-depth documentation of all methods for parameters estimation</span>
<span class="sd">        will be available soon. For now, please refer to the mentioned</span>
<span class="sd">        references.</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>
<span class="sd">        [1] Book: Hayes, M. H. (2009). Statistical digital signal processing</span>
<span class="sd">            and modeling. John Wiley &amp; Sons.</span>
<span class="sd">        [2] Dissertation (Portuguese): Zipf, J. G. F. (2011). Classificação,</span>
<span class="sd">            análise estatística e novas estratégias de algoritmos LMS de passo</span>
<span class="sd">            variável.</span>
<span class="sd">        [3] Wikipedia entry on Least Mean Squares</span>
<span class="sd">            https://en.wikipedia.org/wiki/Least_mean_squares_filter</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">y</span><span class="p">,</span> <span class="n">n_theta</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">xi</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initial_values</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">psi</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_theta</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
            <span class="n">psi_tmp</span> <span class="o">=</span> <span class="n">psi</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">xi</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">psi_tmp</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">theta</span><span class="p">[:,</span> <span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
            <span class="n">theta</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span>
                <span class="n">theta</span><span class="p">[:,</span> <span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mu</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_gama</span><span class="p">)</span>
                <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mu</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">xi</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">psi_tmp</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="n">theta</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span></div>

<div class="viewcode-block" id="Estimators.least_mean_squares_fourth"><a class="viewcode-back" href="../../../code.html#sysidentpy.parameter_estimation.estimators.Estimators.least_mean_squares_fourth">[docs]</a>    <span class="k">def</span> <span class="nf">least_mean_squares_fourth</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">psi</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Parameter estimation using the  LMS Fourth filter.</span>

<span class="sd">        When the leakage factor, gama, is set to 0 then there is no</span>
<span class="sd">        leakage in the estimation process.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        psi : ndarray of floats</span>
<span class="sd">            The information matrix of the model.</span>
<span class="sd">        y_train : array-like of shape = y_training</span>
<span class="sd">            The data used to training the model.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        theta : array-like of shape = number_of_model_elements</span>
<span class="sd">            The estimated parameters of the model.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        A more in-depth documentation of all methods for parameters estimation</span>
<span class="sd">        will be available soon. For now, please refer to the mentioned</span>
<span class="sd">        references.</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>
<span class="sd">        [1] Book: Hayes, M. H. (2009). Statistical digital signal processing</span>
<span class="sd">            and modeling. John Wiley &amp; Sons.</span>
<span class="sd">        [2] Dissertation (Portuguese): Zipf, J. G. F. (2011). Classificação,</span>
<span class="sd">            análise estatística e novas estratégias de algoritmos LMS de passo</span>
<span class="sd">            variável.</span>
<span class="sd">        [3] Manuscript:Gui, G., Mehbodniya, A., &amp; Adachi, F. (2013).</span>
<span class="sd">            Least mean square/fourth algorithm with application to sparse</span>
<span class="sd">            channel estimation. arXiv preprint arXiv:1304.3911.</span>
<span class="sd">            https://arxiv.org/pdf/1304.3911.pdf</span>
<span class="sd">        [4] Manuscript: Nascimento, V. H., &amp; Bermudez, J. C. M. (2005, March).</span>
<span class="sd">            When is the least-mean fourth algorithm mean-square stable?</span>
<span class="sd">            In Proceedings.(ICASSP&#39;05). IEEE International Conference on</span>
<span class="sd">            Acoustics, Speech, and Signal Processing, 2005.</span>
<span class="sd">            (Vol. 4, pp. iv-341). IEEE.</span>
<span class="sd">            http://www.lps.usp.br/vitor/artigos/icassp05.pdf</span>
<span class="sd">        [5] Wikipedia entry on Least Mean Squares</span>
<span class="sd">            https://en.wikipedia.org/wiki/Least_mean_squares_filter</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">y</span><span class="p">,</span> <span class="n">n_theta</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">xi</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initial_values</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">psi</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_theta</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
            <span class="n">psi_tmp</span> <span class="o">=</span> <span class="n">psi</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">xi</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">psi_tmp</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">theta</span><span class="p">[:,</span> <span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
            <span class="n">theta</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span>
                <span class="n">theta</span><span class="p">[:,</span> <span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mu</span> <span class="o">*</span> <span class="n">psi_tmp</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">xi</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">**</span> <span class="mi">3</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="n">theta</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span></div>

<div class="viewcode-block" id="Estimators.least_mean_squares_mixed_norm"><a class="viewcode-back" href="../../../code.html#sysidentpy.parameter_estimation.estimators.Estimators.least_mean_squares_mixed_norm">[docs]</a>    <span class="k">def</span> <span class="nf">least_mean_squares_mixed_norm</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">psi</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Parameter estimation using the Mixed-norm LMS filter.</span>

<span class="sd">        The weight factor controls the proportions of the error norms</span>
<span class="sd">        and offers an extra degree of freedom within the adaptation.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        psi : ndarray of floats</span>
<span class="sd">            The information matrix of the model.</span>
<span class="sd">        y_train : array-like of shape = y_training</span>
<span class="sd">            The data used to training the model.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        theta : array-like of shape = number_of_model_elements</span>
<span class="sd">            The estimated parameters of the model.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        A more in-depth documentation of all methods for parameters estimation</span>
<span class="sd">        will be available soon. For now, please refer to the mentioned</span>
<span class="sd">        references.</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>
<span class="sd">        [1] Chambers, J. A., Tanrikulu, O., &amp; Constantinides, A. G. (1994).</span>
<span class="sd">            Least mean mixed-norm adaptive filtering.</span>
<span class="sd">            Electronics letters, 30(19), 1574-1575.</span>
<span class="sd">            https://ieeexplore.ieee.org/document/326382</span>
<span class="sd">        [2] Dissertation (Portuguese): Zipf, J. G. F. (2011). Classificação,</span>
<span class="sd">            análise estatística e novas estratégias de algoritmos LMS de passo</span>
<span class="sd">            variável.</span>
<span class="sd">        [3] Wikipedia entry on Least Mean Squares</span>
<span class="sd">            https://en.wikipedia.org/wiki/Least_mean_squares_filter</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">y</span><span class="p">,</span> <span class="n">n_theta</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">xi</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initial_values</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">psi</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_theta</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
            <span class="n">psi_tmp</span> <span class="o">=</span> <span class="n">psi</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">xi</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">psi_tmp</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">theta</span><span class="p">[:,</span> <span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
            <span class="n">theta</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span>
                <span class="n">theta</span><span class="p">[:,</span> <span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mu</span>
                <span class="o">*</span> <span class="n">psi_tmp</span>
                <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">xi</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
                <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_weight</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weight</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">xi</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="n">theta</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span></div></div>
</pre></div>

              </div>
              
        
        <div class='prev-next-bottom'>
            

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Wilson Rocha, Luan Pascoal, Samuel Oliveira, Samir Martins<br/>
        
            &copy; Copyright 2020, Wilson Rocha, Luan Pascoal, Samuel Oliveira, Samir Martins.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../../../_static/js/index.d3f166471bb80abb5163.js"></script>


    
  </body>
</html>