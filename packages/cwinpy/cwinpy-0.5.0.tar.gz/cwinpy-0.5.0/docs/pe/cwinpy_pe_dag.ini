[run]
# the base directory for the analysis **output**
basedir = root

######### Condor DAG specific inputs ########
[dag]
# the location of the directory to contain the Condor DAG submission files
# (defaults to "basedir/submit")
;submit = 

# the prefix of the name for the Condor DAGMan submit file (defaults to
# "dag_cwinpy_pe"). "dag" will always be prepended.
;name =

# a flag specifying whether to automatically submit the DAG after its creation
# (defaults to False)
submitdag = False

# a flag saying whether to build the DAG (defaults to True)
;build =

# any additional submittion options (defaults to None)
;submit_options =

# the scheduler (Condor or Slurm) to use (defaults to Condor)
;scheduler

######## cwinpy_knope Job options ########
[job]
# the location of the cwinpy_knope executable to use (defaults to try and find
# cwinpy_knope in the current user PATH)
;executable =

# the prefix of the name for the Condor Job submit file (defaults to
# "cwinpy_knope")
;name =

# set the Condor universe (defaults to "vanilla") 
;universe =

# directory location for the output from stdout from the Job (defaults to
# "basedir/out")
;out =

# directory location for the output from stderr from the Job (defaults to
# "basedir/error")
;error =

# directory location for any logging information from the jobs (defaults to
# "basedir/log")
;log =

# the location of the directory to contain the Condor job submission files
# (defaults to "basedir/submit")
;submit =

# set to allow the jobs to access local environment variables (defaults to
# False)
getenv = True

# the amount of available memory request for each job (defaults to 4 Gb)
# [Note: this is required for vanilla jobs on LIGO Scientific Collaboration
# computer clusters]
;reqmem =

# the number of CPUs the job requires (defaults to 1, cwinpy_knope is not
# currently parallelised in any way)
;reqcpus =

# additional Condor job requirements (defaults to None)
;requirements =

# set how many times the DAG will retry a job on failure (default to 0)
;retry =

# Job accounting group and user [Note: these are required on LIGO Scientific
# Collaboration computer cluster, but may otherwise be left out]
;accounting_group =
accounting_group_user = albert.einstein

######## PE specific options ########
[pe]
# The pulsar parameter files, where all files are expected to have the
# extension ".par". This can either be:
#  - the path to a single file (if running with a single source)
#  - a list of parameter files
#  - a directory (or glob-able directory pattern) containing parameter files
#  - a combination of a list of directories and/or files
pulsars = /root/pulsars

# The number of parallel runs for each pulsar. These will be combined to
# create the final output. This defaults to 1.
;n_parallel =

# The directory within basedir into which to output the results in individual
# directories named using the PSRJ name (defaults to "results")
;results =

# Pulsar "injection" parameter files containing simulated signal parameters to
# add to the data. If not given then no injections will be performed. If given
# it should be in the same style as the "pulsars" section.
;injections =

# Locations of heterodyned data files produced at twice the rotation frequency
# of the source. This must be a dictionary keyed to detector names. The value
# of each detector-keyed item can be:
#  - the path to a single file (if analysing one detector)
#  - a directory (or glob-able directory pattern) containing (only) data files
#  - a list of files (or directories/directory patterns)
#  - a dictionary keyed to pulsar PSRJ names containing the full paths to the
#    associated data file
# The file name or path for each dataset must contain the associated pulsar
# PSRJ name.
# This can alternatively be just given as "data-file"
data-file-2f = {"H1": "/root/detector1/2f/*/*", "L1": "/root/detector2/2f/*/*"}

# Locations of heterodyned data files produced at the rotation frequency of the
# source (if required). This must be a dictionary keyed to detector names. The value of each
# detector-keyed item can be:
#  - the path to a single file (if analysing one detector)
#  - a directory (or glob-able directory pattern) containing (only) data files
#  - a list of files (or directories/directory patterns)
#  - a dictionary keyed to pulsar PSRJ names containing the full paths to the
#    associated data file
# The file name or path for each dataset must contain the associated pulsar
# PSRJ name. [Note: this is not required if only analysing data at twice the
# rotation frequency]
data-file-1f = {"H1": "/root/detector1/1f/*/*", "L1": "/root/detector2/1f/*/*"}

# Flags to set to generate simulated Gaussian noise to analyse, if data files
# are not given. "fake-asd-1f" is used to produce simulated noise at the source
# rotation frequency and "fake-asd-2f" (or just "fake-asd" is used to produce
# simulated noise at twice the source rotation frequency). The values these can
# take are:
#  - a list of detectors, in which case the detector's design sensitivity curve
#    will be used when generating the noise for each pulsar
#  - a dictionary, keyed to detector names, either giving a value that is an
#    amplitude spectral density value to be used, or a file containing a
#    frequency series of amplitude spectral densities to use
;fake-asd-1f =
;fake-asd-2f =

# Flags to set the start time, end time and time step for the fake data
# generation. Either both 'fake-start' and 'fake-end' must be set, or
# neither should be set. Each of these can either be:
#  - a single integer of float giving the GPS time/time step
#  - a dictionary keyed to the detector names containing the value for the
#    given detector
# If not given the fake data for any required detectors will start at a GPS
# time of 1000000000 and end at 1000086400 (i.e., for one day), with a time
# step of 60 seconds
;fake-start =
;fake-end =
;fake-dt =


# Locations of the Earth and Sun ephemerides. If not given then the ephemerides
# will be automatically determined from the pulsar parameter information. The
# values can either be a string giving a single file path in each case, or a
# dictionary, keyed to pulsar names, containing file paths.
;ephem-earth =
;ephem-sun =

# The prior distributions to use for each pulsar. The value of this can either
# be:
#  - a single prior file (in bilby format) to use for all pulsars
#  - a list of prior files, where each filename contains the PSRJ name of the
#    associated pulsar
#  - a directory, or glob-able directory pattern, containing the prior files,
#    where each filename contains the PSRJ name of the associated pulsar
#  - a dictionary with prior file names keyed to the associated pulsar
# If not given then default priors will be used. If using data at just twice
# the rotation frequency the default priors are:
#   h0 = Uniform(minimum=0.0, maximum=1.0e-22, name='h0')
#   phi0 = Uniform(minimum=0.0, maximum=pi, name='phi0')
#   iota = Sine(minimum=0.0, maximum=pi, name='iota')
#   psi = Uniform(minimum=0.0, maximum=pi/2, name='psi')
# For data at just the rotation frequency the default priors are:
#   c21 = Uniform(minimum=0.0, maximum=1.0e-22, name='c21')
#   phi21 = Uniform(minimum=0.0, maximum=2*pi, name='phi21')
#   iota = Sine(minimum=0.0, maximum=pi, name='iota')
#   psi = Uniform(minimum=0.0, maximum=pi/2, name='psi')
# And, for data at both frequencies, the default priors are:
#   c21 = Uniform(minimum=0.0, maximum=1.0e-22, name='c21')
#   c22 = Uniform(minimum=0.0, maximum=1.0e-22, name='c22')
#   phi21 = Uniform(minimum=0.0, maximum=2*pi, name='phi21')
#   phi22 = Uniform(minimum=0.0, maximum=2*pi, name='phi22')
#   iota = Sine(minimum=0.0, maximum=pi, name='iota')
#   psi = Uniform(minimum=0.0, maximum=pi/2, name='psi')
priors = /root/priors

# Flag to say whether to output the injected/recovered signal-to-noise ratios
# (defaults to False)
;output_snr =

# The location within basedir for the cwinpy_knope configuration files
# generated to each source (defaults to "configs")
;config =

# The stochastic sampling package to use (defaults to "dynesty")
;sampler =

# A dictionary of any keyword arguments required by the sampler package
# (defaults to None)
;sampler_kwargs =

# A flag to set whether to use the numba-enable likelihood function (defaults
# to False)
;numba =
