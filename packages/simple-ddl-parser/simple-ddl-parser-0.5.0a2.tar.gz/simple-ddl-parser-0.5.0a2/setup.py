# -*- coding: utf-8 -*-
from setuptools import setup

packages = \
['simple_ddl_parser']

package_data = \
{'': ['*']}

install_requires = \
['ply>=3.11,<4.0']

entry_points = \
{'console_scripts': ['sdp = simple_ddl_parser.cli:main']}

setup_kwargs = {
    'name': 'simple-ddl-parser',
    'version': '0.5.0a2',
    'description': 'Simple DDL Parser to parse SQL & HQL ddl files to json/python dict with full information about columns: types, defaults, primary keys, etc.',
    'long_description': '\nSimple DDL Parser\n-----------------\n\n\n.. image:: https://img.shields.io/pypi/v/simple-ddl-parser\n   :target: https://img.shields.io/pypi/v/simple-ddl-parser\n   :alt: badge1\n \n.. image:: https://img.shields.io/pypi/l/simple-ddl-parser\n   :target: https://img.shields.io/pypi/l/simple-ddl-parser\n   :alt: badge2\n \n.. image:: https://img.shields.io/pypi/pyversions/simple-ddl-parser\n   :target: https://img.shields.io/pypi/pyversions/simple-ddl-parser\n   :alt: badge3\n \n\nHow to install\n^^^^^^^^^^^^^^\n\n.. code-block:: bash\n\n\n       pip install simple-ddl-parser\n\nParser tested on different DDLs for PostgreSQL & Hive.\nTypes that are used in your DB does not matter, so parser must also work successfuly to any DDL for SQL DB.\n\nIf you have samples that cause an error - please open the issue (but don\'t forget to add ddl example), I will be glad to fix it.\n\nThis parser take as input SQL DDL statements or files, for example like this:\n\n.. code-block:: sql\n\n\n       create table prod.super_table\n   (\n       data_sync_id bigint not null default 0,\n       id_ref_from_another_table int REFERENCES another_table (id)\n       sync_count bigint not null REFERENCES count_table (count),\n       sync_mark timestamp  not  null,\n       sync_start timestamp  not null default now(),\n       sync_end timestamp  not null,\n       message varchar(2000) null,\n       primary key (data_sync_id, sync_start)\n   );\n\nAnd produce output like this (information about table name, schema, columns, types and properties):\n\n.. code-block:: python\n\n\n       [\n           {\n               "columns": [\n                   {\n                       "name": "data_sync_id", "type": "bigint", "size": None, \n                       "nullable": False, "default": None, "references": None,\n                   },\n                   {\n                       "name": "id_ref_from_another_table", "type": "int", "size": None,\n                       "nullable": False, "default": None, "references": {"table": "another_table", "schema": None, "column": "id"},\n                   },\n                   {\n                       "name": "sync_count", "type": "bigint", "size": None,\n                       "nullable": False, "default": None, "references": {"table": "count_table", "schema": None, "column": "count"},\n                   },\n                   {\n                       "name": "sync_mark", "type": "timestamp", "size": None,\n                       "nullable": False, "default": None, "references": None,\n                   },\n                   {\n                       "name": "sync_start", "type": "timestamp", "size": None,\n                       "nullable": False, "default": None, "references": None,\n                   },\n                   {\n                       "name": "sync_end", "type": "timestamp", "size": None,\n                       "nullable": False, "default": None, "references": None,\n                   },\n                   {\n                       "name": "message", "type": "varchar", "size": 2000,\n                       "nullable": False, "default": None, "references": None,\n                   },\n               ],\n               "primary_key": ["data_sync_id", "sync_start"],\n               "table_name": "super_table",\n               "schema": "prod",\n               "alter": {}\n           }\n       ]\n\nOr one more example\n\n.. code-block:: sql\n\n\n   CREATE TABLE "paths" (\n     "id" int PRIMARY KEY,\n     "title" varchar NOT NULL,\n     "description" varchar(160),\n     "created_at" timestamp,\n     "updated_at" timestamp\n   );\n\nand result\n\n.. code-block:: python\n\n           [{\n           \'columns\': [\n               {\'name\': \'id\', \'type\': \'int\', \'nullable\': False, \'size\': None, \'default\': None, \'references\': None}, \n               {\'name\': \'title\', \'type\': \'varchar\', \'nullable\': False, \'size\': None, \'default\': None, \'references\': None}, \n               {\'name\': \'description\', \'type\': \'varchar\', \'nullable\': False, \'size\': 160, \'default\': None, \'references\': None}, \n               {\'name\': \'created_at\', \'type\': \'timestamp\', \'nullable\': False, \'size\': None, \'default\': None, \'references\': None}, \n               {\'name\': \'updated_at\', \'type\': \'timestamp\', \'nullable\': False, \'size\': None, \'default\': None, \'references\': None}], \n           \'primary_key\': [\'id\'], \n           \'table_name\': \'paths\', \n           \'schema\': None,\n           \'alter\': {}\n           }]\n\nIf you pass file or text block with more when 1 CREATE TABLE statement when result will be list of such dicts. For example:\n\nInput:\n\n.. code-block:: sql\n\n\n   CREATE TABLE "countries" (\n     "id" int PRIMARY KEY,\n     "code" varchar(4) NOT NULL,\n     "name" varchar NOT NULL\n   );\n\n   CREATE TABLE "path_owners" (\n     "user_id" int,\n     "path_id" int,\n     "type" int DEFAULT 1\n   );\n\nOutput:\n\n.. code-block:: python\n\n\n       [\n           {\'columns\': [\n               {\'name\': \'id\', \'type\': \'int\', \'size\': None, \'nullable\': False, \'default\': None, \'references\': None}, \n               {\'name\': \'code\', \'type\': \'varchar\', \'size\': 4, \'nullable\': False, \'default\': None, \'references\': None}, \n               {\'name\': \'name\', \'type\': \'varchar\', \'size\': None, \'nullable\': False, \'default\': None, \'references\': None}], \n            \'primary_key\': [\'id\'], \n            \'table_name\': \'countries\', \n            \'schema\': None}, \n           {\'columns\': [\n               {\'name\': \'user_id\', \'type\': \'int\', \'size\': None, \'nullable\': False, \'default\': None, \'references\': None}, \n               {\'name\': \'path_id\', \'type\': \'int\', \'size\': None, \'nullable\': False, \'default\': None, \'references\': None}, \n               {\'name\': \'type\', \'type\': \'int\', \'size\': None, \'nullable\': False, \'default\': 1, \'references\': None}], \n            \'primary_key\': [], \n            \'table_name\': \'path_owners\', \n            \'schema\': None,\n            \'alter\': {}}\n       ]\n\nALTER statements\n^^^^^^^^^^^^^^^^\n\nRight now added support only for ALTER statements with FOREIGEIN key\n\nFor example, if in your ddl after table defenitions (create table statements) you have ALTER table statements like this:\n\n.. code-block:: sql\n\n\n   ALTER TABLE "material_attachments" ADD FOREIGN KEY ("material_id", "material_title") REFERENCES "materials" ("id", "title");\n\nThis statements will be parsed and information about them putted inside \'alter\' key in table\'s dict.\nFor example, please check alter statement tests - **tests/test_alter_statements.py**\n\nHow to use\n----------\n\nFrom python code\n^^^^^^^^^^^^^^^^\n\n.. code-block:: python\n\n       from simple_ddl_parser import DDLParser\n\n\n       parse_results = DDLParser("""create table dev.data_sync_history(\n           data_sync_id bigint not null,\n           sync_count bigint not null,\n           sync_mark timestamp  not  null,\n           sync_start timestamp  not null,\n           sync_end timestamp  not null,\n           message varchar(2000) null,\n           primary key (data_sync_id, sync_start)\n       ); """).run()\n\n       print(parse_results)\n\nTo parse from file\n^^^^^^^^^^^^^^^^^^\n\n.. code-block:: python\n\n\n       from simple_ddl_parser import parse_from_file\n\n       result = parse_from_file(\'tests/sql/test_one_statement.sql\')\n       print(result)\n\nFrom command line\n^^^^^^^^^^^^^^^^^\n\nsimple-ddl-parser is installed to environment as command **sdp**\n\n.. code-block:: bash\n\n\n       sdp path_to_ddl_file\n\n       # for example:\n\n       sdp tests/sql/test_two_tables.sql\n\nYou will see the output in **schemas** folder in file with name **test_two_tables_schema.json**\n\nIf you want to have also output in console - use **-v** flag for verbose.\n\n.. code-block:: bash\n\n\n       sdp tests/sql/test_two_tables.sql -v\n\nIf you don\'t want to dump schema in file and just print result to the console, use **--no-dump** flag:\n\n.. code-block:: bash\n\n\n       sdp tests/sql/test_two_tables.sql --no-dump\n\nYou can provide target path where you want to dump result with argument **-t**\\ , **--targer**\\ :\n\n.. code-block:: bash\n\n\n       sdp tests/sql/test_two_tables.sql -t dump_results/\n\nMore examples & tests\n^^^^^^^^^^^^^^^^^^^^^\n\nYou can find in **tests/** folder.\n\nDump result in json\n^^^^^^^^^^^^^^^^^^^\n\nTo dump result in json use argument .run(dump=True)\n\nYou also can provide a path where you want to have a dumps with schema with argument .run(dump_path=\'folder_that_use_for_dumps/\')\n\nTODO in next Releases (if you don\'t see feature that you need - open the issue)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n#. Support CREATE INDEX statements\n#. Support ARRAYs\n#. Support CREATE SEQUENCE statements\n\nHistorical context\n^^^^^^^^^^^^^^^^^^\n\nThis library is an extracted parser code from https://github.com/xnuinside/fakeme (Library for fake relation data generation, that I used in several work projects, but did not have time to make from it normal open source library)\n\nFor one of the work projects I needed to convert SQL ddl to Python ORM models in auto way and I tried to use https://github.com/andialbrecht/sqlparse but it works not well enough with ddl for my case (for example, if in ddl used lower case - nothing works, primary keys inside ddl are mapped as column name not reserved word and etc.).\nSo I remembered about Parser in Fakeme and just extracted it & improved. \n\nHow to run tests\n^^^^^^^^^^^^^^^^\n\n.. code-block:: bash\n\n\n       git clone https://github.com/xnuinside/simple-ddl-parser.git\n       cd simple-ddl-parser\n       poetry install # if you use poetry\n       # or use `pip install .`\n       pytest tests/ -vv\n\nHow to contribute\n-----------------\n\nPlease describe issue that you want to solve and open the PR, I will review it as soon as possible.\n\nAny questions? Ping me in Telegram: https://t.me/xnuinside \n\nChangelog\n---------\n\n**v0.5.0**\n\n\n#. Added support for UNIQUE column attribute\n#. Add command line arg to pass folder with ddls (parse multiple files)\n#. Added support for CHECK Constratint\n#. Added support for FOREIGN Constratint in ALTER TABLE\n\n**v0.4.0**\n\n\n#. Added support schema for table in REFERENCES statement in column defenition\n#. Added base support fot Alter table statements (added \'alters\' key in table)\n#. Added command line arg to pass path to get the output results\n#. Fixed incorrect null fields parsing\n\n**v0.3.0**\n\n\n#. Added support for REFERENCES statement in column defenition\n#. Added command line\n',
    'author': 'Iuliia Volkova',
    'author_email': 'xnuinside@gmail.com',
    'maintainer': None,
    'maintainer_email': None,
    'url': 'https://github.com/xnuinside/simple-ddl-parser',
    'packages': packages,
    'package_data': package_data,
    'install_requires': install_requires,
    'entry_points': entry_points,
    'python_requires': '>=3.6,<4.0',
}


setup(**setup_kwargs)
